# ðŸ“š Mini RAG-based AI Knowledge Assistant

A simple Retrieval-Augmented Generation (RAG) app where you can upload PDFs and ask questions based on their content.  
The system uses:

- **SentenceTransformers** to create text embeddings
- **ChromaDB** as a vector database
- **Groq Llama 3.1** models for answer generation
- **Streamlit** for the web UI

---

## âœ¨ Features

- Upload one or more PDF files
- Index documents into a vector database (Chroma)
- Ask natural language questions about the PDFs
- Retrieval-Augmented Generation (RAG) pipeline
- Shows **retrieved context chunks** used by the model
- Conversation-style **chat history**
- Button to **clear** the vector database

---

## ðŸ§± Project Structure

```text
mini_rag_assistant/
â”‚
â”œâ”€â”€ app.py          # Streamlit UI
â”œâ”€â”€ rag_core.py     # Core RAG logic (PDF â†’ chunks â†’ embeddings â†’ retrieval â†’ LLM)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ docs/       # PDFs are stored here (not committed to Git)
â””â”€â”€ chroma_store/   # Local ChromaDB files (ignored in Git)

Tech Stack: 
Python 3.10+
Streamlit
SentenceTransformers
ChromaDB
Groq LLM API
Llama 3.1 8B Instant (llama-3.1-8b-instant)
